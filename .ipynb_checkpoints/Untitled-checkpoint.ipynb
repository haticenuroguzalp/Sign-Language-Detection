{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b3a5cf44",
   "metadata": {},
   "source": [
    "LIBRARIES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "988bd3b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from keras.models import Sequential \n",
    "from keras.layers import Conv2D, MaxPooling2D, Activation, Dropout, Flatten, Dense\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator, img_to_array, load_img\n",
    "from tensorflow.keras.models import load_model\n",
    "import matplotlib.pyplot as plt\n",
    "from glob import glob\n",
    "import cv2\n",
    "import numpy as np\n",
    "import mediapipe as mp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88804d3b",
   "metadata": {},
   "source": [
    "IMAGE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3ecb7f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path = \"alphabet/Train_Alphabet/\"\n",
    "test_path = \"alphabet/Test_Alphabet/\"\n",
    "img = \"alphabet/Train_Alphabet/A/00c14c44-e77c-43f7-a027-0c501395c00d.rgb_0000.png\"\n",
    "\n",
    "\n",
    "img1 = load_img(img)\n",
    "plt.imshow(img1)\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "852db7ca",
   "metadata": {},
   "source": [
    "IMAGE RESIZING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ee4959f",
   "metadata": {},
   "outputs": [],
   "source": [
    "image = cv2.imread(img)\n",
    "\n",
    "\n",
    "image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "# Görüntünün orijinal boyutlarını al\n",
    "original_height, original_width = image_rgb.shape[:2]\n",
    "\n",
    "print(f'Orijinal Boyutlar: {original_width}x{original_height}')\n",
    "\n",
    "# Yeni boyutları belirle\n",
    "new_width = 224\n",
    "new_height = 224\n",
    "\n",
    "# Görüntüyü yeniden boyutlandır\n",
    "resized_image = cv2.resize(image_rgb, (new_width, new_height))\n",
    "\n",
    "print(f'Yeni Boyutlar: {new_width}x{new_height}')\n",
    "\n",
    "# Orijinal ve yeniden boyutlandırılmış görüntüleri göster\n",
    "plt.figure(figsize=(10, 5))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.title('Orijinal Görüntü')\n",
    "plt.imshow(image_rgb)\n",
    "plt.axis('off')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.title('Yeniden Boyutlandırılmış Görüntü')\n",
    "plt.imshow(resized_image)\n",
    "plt.axis('off')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "123dc68a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(512, 513, 3)\n",
      "NumberOfClass:  27\n"
     ]
    }
   ],
   "source": [
    "x = img_to_array(img1)\n",
    "print(x.shape)\n",
    "\n",
    "className = glob(train_path + '/*' )\n",
    "numberOfClass = len(className)\n",
    "print(\"NumberOfClass: \",numberOfClass)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "75f78aa4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(512, 513, 3)\n",
      "NumberOfClass:  27\n"
     ]
    }
   ],
   "source": [
    "className1 = glob(test_path + '/*' )\n",
    "numberOfClass1 = len(className1)\n",
    "y = img_to_array(img3)\n",
    "print(y.shape)\n",
    "print(\"NumberOfClass: \",numberOfClass1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92dc6fd5",
   "metadata": {},
   "source": [
    "CNN MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "206b08b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32,(3,3),input_shape = (224,224,3)))\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(MaxPooling2D())\n",
    "\n",
    "model.add(Conv2D(32,(3,3)))\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(MaxPooling2D())\n",
    "\n",
    "model.add(Conv2D(64,(3,3)))\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(MaxPooling2D())\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(1024))\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(numberOfClass)) # output\n",
    "model.add(Activation(\"softmax\"))\n",
    "\n",
    "model.compile(loss = \"categorical_crossentropy\",\n",
    "              optimizer = \"rmsprop\",\n",
    "              metrics = [\"accuracy\"])\n",
    "\n",
    "batch_size = 30"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b43207d",
   "metadata": {},
   "source": [
    "DATA GENERATION - TRAIN - TEST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ad370df",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train_datagen = ImageDataGenerator(rescale= 1./255,\n",
    "                   shear_range = 0.3,\n",
    "                   horizontal_flip=True,\n",
    "                   zoom_range = 0.3)\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale= 1./255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "        train_path, \n",
    "        target_size= (224, 224),\n",
    "        batch_size = batch_size,\n",
    "        color_mode= \"rgb\",\n",
    "        class_mode= \"categorical\")\n",
    "\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "        test_path, \n",
    "        target_size= (224,224),\n",
    "        batch_size = batch_size,\n",
    "        color_mode= \"rgb\",\n",
    "        class_mode= \"categorical\")\n",
    "\n",
    "hist = model.fit_generator(\n",
    "        generator = train_generator,\n",
    "        steps_per_epoch = 2700 // batch_size,\n",
    "        epochs=50,\n",
    "        validation_data = test_generator,\n",
    "        validation_steps = 1200 // batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "665fed15",
   "metadata": {},
   "source": [
    "MODEL SAVE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "cf6ff7f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model.save_weights(\"sign_language_hist.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b6c6b2e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])\n"
     ]
    }
   ],
   "source": [
    "print(hist.history.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9140166",
   "metadata": {},
   "source": [
    "MODEL EVALUATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "640398a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(hist.history.keys())\n",
    "plt.plot(hist.history[\"loss\"], label = \"Train Loss\")\n",
    "plt.plot(hist.history[\"val_loss\"], label = \"Validation Loss\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "plt.figure()\n",
    "plt.plot(hist.history[\"accuracy\"], label = \"Train acc\")\n",
    "plt.plot(hist.history[\"val_accuracy\"], label = \"Validation acc\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3979254c",
   "metadata": {},
   "outputs": [],
   "source": [
    "SAVE HISTORY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8451c4f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import json\n",
    "with open(\"sign_language_hist.json\",\"w\") as f:\n",
    "    json.dump(hist.history, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8e7d841",
   "metadata": {},
   "outputs": [],
   "source": [
    "LOAD HISTORY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a85f752",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "import codecs\n",
    "import json\n",
    "with codecs.open(\"sign_language_hist.json\", \"r\",encoding = \"utf-8\") as f:\n",
    "    h = json.loads(f.read())\n",
    "plt.plot(h[\"loss\"], label = \"Train Loss\")\n",
    "plt.plot(h[\"val_loss\"], label = \"Validation Loss\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "plt.figure()\n",
    "plt.plot(h[\"accuracy\"], label = \"Train acc\")\n",
    "plt.plot(h[\"val_accuracy\"], label = \"Validation acc\")\n",
    "plt.legend()\n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "847d977f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights(\"sign_language_hist.h5\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f851ea5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "datagen = ImageDataGenerator()\n",
    "train_generator = datagen.flow_from_directory(\n",
    "    train_path,\n",
    "    target_size=(224, 224), \n",
    "    batch_size=30,\n",
    "    class_mode='categorical'\n",
    ")\n",
    "\n",
    "\n",
    "class_names = list(train_generator.class_indices.keys())\n",
    "print(\"Sınıf isimleri:\", class_names)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c5a966d",
   "metadata": {},
   "source": [
    "MEDIAPIPE SOLUTIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8fc59e6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "mp_hands = mp.solutions.hands\n",
    "hands = mp_hands.Hands(max_num_hands=1, min_detection_confidence=0.7)\n",
    "mp_drawing = mp.solutions.drawing_utils\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f985a6ae",
   "metadata": {},
   "source": [
    "PREDICTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34c5f754",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        print(\"Kameradan görüntü alınamadı\")\n",
    "        break\n",
    "    \n",
    "    \n",
    "    rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    result = hands.process(rgb_frame)\n",
    "    \n",
    "    if result.multi_hand_landmarks:\n",
    "        for hand_landmarks in result.multi_hand_landmarks:\n",
    "\n",
    "            h, w, c = frame.shape\n",
    "            x_min = w\n",
    "            y_min = h\n",
    "            x_max = 0\n",
    "            y_max = 0\n",
    "            for landmark in hand_landmarks.landmark:\n",
    "                x = int(landmark.x * w)\n",
    "                y = int(landmark.y * h)\n",
    "                if x < x_min:\n",
    "                    x_min = x\n",
    "                if y < y_min:\n",
    "                    y_min = y\n",
    "                if x > x_max:\n",
    "                    x_max = x\n",
    "                if y > y_max:\n",
    "                    y_max = y\n",
    "\n",
    "            hand_frame = frame[y_min:y_max, x_min:x_max]\n",
    "            \n",
    "            if hand_frame.size != 0:\n",
    "\n",
    "                img = cv2.resize(hand_frame, (224, 224))\n",
    "                img = np.expand_dims(img, axis=0)\n",
    "                img = img / 255.0 \n",
    "\n",
    "                predictions = model.predict(img)\n",
    "                predicted_class = np.argmax(predictions[0])\n",
    "                predicted_label = class_names[predicted_class]\n",
    "\n",
    "                cv2.rectangle(frame, (x_min, y_min), (x_max, y_max), (255, 0, 0), 2)\n",
    "                cv2.putText(frame, predicted_label, (x_min, y_min-10), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n",
    "    \n",
    "    cv2.imshow('Kamera', frame)\n",
    "    \n",
    "    # 'q' tuşuna basıldığında döngüyü kır ve çık\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "hands.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
